{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 13:40:41.804077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-07 13:40:41.804109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-07 13:40:41.805253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-07 13:40:41.812145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 13:40:42.738763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "from tensorflow_gan.examples.mnist.util import mnist_frechet_distance\n",
    "\n",
    "from src.sarnet_vae import *\n",
    "from src.semidense import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "- set a particural digit to reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT = 5\n",
    "image_dim = 28\n",
    "n_pixels = image_dim * image_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "- Load images from the MNIST dataset and scale them to range [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train images\n",
    "images = np.load(\"./data/train_images.npy\")\n",
    "labels = np.load(\"./data/train_labels.npy\")\n",
    "images = images[labels == DIGIT]\n",
    "\n",
    "# Load test images\n",
    "test_images = np.load(\"./data/test_images.npy\")\n",
    "test_labels = np.load(\"./data/test_labels.npy\")\n",
    "test_images = test_images[test_labels == DIGIT]\n",
    "\n",
    "# Raw data\n",
    "raw_data = images\n",
    "raw_test_data = test_images\n",
    "\n",
    "# Standarized data\n",
    "standarized_data = images / 255\n",
    "standarized_test_data = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(train_data, test_data, batch_size=64, device=\"cuda\"):\n",
    "    \"\"\"Create torch dataloader from the numpy data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : numpy.ndarray\n",
    "        The training data.\n",
    "    test_data : numpy.ndarray\n",
    "        The testing data.\n",
    "    batch_size : int, optional\n",
    "        The batch size for the DataLoader (default is 64).\n",
    "    device : str, optional\n",
    "        The device on which the data will be moved (default is cuda).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        DataLoader object for the training data with tensors of shape (1,image_dim,image_dim).\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        DataLoader object for the testing data with tensors of shape (1,image_dim,image_dim).\n",
    "    \"\"\"\n",
    "    X = train_data.reshape(-1, 1, image_dim, image_dim)\n",
    "    X = torch.tensor(X).float().to(device)\n",
    "    train_loader = DataLoader(TensorDataset(X), batch_size=64, shuffle=True)\n",
    "\n",
    "    X_test = test_data.reshape(-1, 1, image_dim, image_dim)\n",
    "    X_test = torch.tensor(X_test).float().to(device)\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(X_test), batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation\n",
    "\n",
    " - the function below generates an image (or multiple images in parallel) using a `sarNET_VAE` model. It can generate an image from scratch (starting with a black patch) or continue generating from a part of existing image.\n",
    "\n",
    " - First, it generates a latent space random vector, which defines the style of the image. Next, it generates the image (or a batch of images) patch by patch. The random vector can be modified to have less variance, resulting in output digits that are \"sharper\" but less diverse.\n",
    "\n",
    "- To stabilize generation process, it blacks out the pixels below a certain threshold - typically, the pixels below a small constant ~0.09 are set to black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_patch(patch_idx, patch_dim, img_size):\n",
    "    \"\"\"\n",
    "    Get the pixel indices of a specific patch in the image.\n",
    "    \"\"\"\n",
    "    row = patch_idx // (img_size // patch_dim)\n",
    "    col = patch_idx % (img_size // patch_dim)\n",
    "    pxl_idxs = [\n",
    "        (row * patch_dim + p_y) * img_size + col * patch_dim + p_x\n",
    "        for p_y in range(patch_dim)\n",
    "        for p_x in range(patch_dim)\n",
    "    ]\n",
    "    return pxl_idxs\n",
    "\n",
    "\n",
    "def init_image(patch_dim, image=None, pixels_seed=0):\n",
    "    \"\"\"\n",
    "    Initialize an image by setting specific patches to zero.\n",
    "    One can use a specific image as a seed to further generation.\n",
    "    \"\"\"\n",
    "    patch_size = patch_dim**2\n",
    "    patches = n_pixels // patch_size\n",
    "\n",
    "    if image is None:\n",
    "        start_image = np.zeros(n_pixels)\n",
    "        indexes_of_patches = list(range(patches - 1))\n",
    "    else:\n",
    "        start_image = copy.deepcopy(image).reshape(n_pixels)\n",
    "\n",
    "        assert pixels_seed % patch_size == 0\n",
    "        indexes_of_patches = list(\n",
    "            range((pixels_seed // patch_size - 1), patches - 1)\n",
    "        )\n",
    "        for i_p in indexes_of_patches:\n",
    "            idxs = get_i_patch(i_p + 1, patch_dim, image_dim)\n",
    "            start_image[idxs] = 0\n",
    "\n",
    "    return start_image, indexes_of_patches\n",
    "\n",
    "\n",
    "def plot_image(image, show_plot=True):\n",
    "    \"\"\"\n",
    "    Plot an image.\n",
    "    \"\"\"\n",
    "    plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(\n",
    "    model,\n",
    "    patch_dim,\n",
    "    latent_dim=10,\n",
    "    image=None,\n",
    "    pixels_seed=0,\n",
    "    th=0,\n",
    "    plot=True,\n",
    "    num_of_images=1,\n",
    "    cust_z=None,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an image (or multiplie images - num_of_images) using a regression sarnet_vae model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The sarnet_vae model used for generating the image.\n",
    "    patch_dim : int\n",
    "        The dimension of the patches to process.\n",
    "    latent_dim : int, optional\n",
    "        The dimension of the latent space (default is 10).\n",
    "    image : numpy.ndarray, optional\n",
    "        The initial image to be used as a base for generation. If None, a blank image is used.\n",
    "    pixels_seed : int, optional\n",
    "        Only applicable if image is not None and num_of_images=1. It's the number of pixels from the base image used as a seed for generation.\n",
    "    th : float, optional\n",
    "        The threshold for pixel values (default is 0).\n",
    "    plot : bool, optional\n",
    "        Whether to plot the generated image (default is True).\n",
    "    num_of_images : int, optional\n",
    "        The number of images for parallel generation (default is 1).\n",
    "    cust_z : torch.Tensor, optional\n",
    "        Custom latent vector to be used for generation. If None, a random vector is generated.\n",
    "    device : str, optional\n",
    "        The device of the latent vector to be moved on\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The generated image as a numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the image and get the indexes of patches to process\n",
    "    start_image, indexes_of_patches = init_image(patch_dim, image=image, pixels_seed=pixels_seed)\n",
    "    start_image = start_image.reshape(1, image_dim * image_dim)\n",
    "    start_image = np.repeat(start_image, num_of_images, axis=0)\n",
    "\n",
    "    if cust_z is not None:\n",
    "        z = cust_z\n",
    "    else:\n",
    "        z = torch.randn(num_of_images, latent_dim).to(device)\n",
    "\n",
    "    min_pixel, min_th = 0, th\n",
    "\n",
    "    # Iterate over the patches to generate the image\n",
    "    for idx in indexes_of_patches:\n",
    "        patch_idxs = get_i_patch(idx, patch_dim, image_dim)\n",
    "\n",
    "        X = start_image.reshape(num_of_images, 1, image_dim, image_dim)\n",
    "        X = torch.tensor(X).float().to(\"cuda\")\n",
    "\n",
    "        Y = model.decode(X, z)\n",
    "\n",
    "        Y = Y.to(\"cpu\").detach().numpy().reshape(num_of_images, -1)\n",
    "        patch_idxs = get_i_patch(idx + 1, patch_dim, image_dim)\n",
    "\n",
    "        Y = Y[:, patch_idxs]\n",
    "\n",
    "        Y[Y < min_th] = min_pixel\n",
    "\n",
    "        start_image[:, patch_idxs] = Y\n",
    "\n",
    "    start_image = start_image.reshape(num_of_images, image_dim, image_dim)\n",
    "\n",
    "    if plot:\n",
    "        plot_image(start_image, show_plot=False)\n",
    "\n",
    "    return start_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and metrics\n",
    "\n",
    "We calculate the Fréchet Inception Distance (FID) score between generated images and MNIST test images. We use `mnist_frechet_distance` function from the tensorflow_gan package. TF_GAN is widely used in projects and research at Google.\n",
    "\n",
    "Unlike the traditional FID calculation, `mnist_frechet_distance` doesn't use the InceptionV3 model. Instead, it uses the TF-GAN MNIST classifier, which has ~99% accuracy. This approach allows for quicker calculations. The function expects the input pixel values to be in the range [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid_score_mnist(generated_images, N):\n",
    "    \"\"\"\n",
    "    Calculate the Fréchet Inception Distance (FID) score between generated images and MNIST test images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    generated_images : list, numpy.ndarray or torch.tensor\n",
    "        The generated images to be evaluated. Should be a iterable list of images with shape (N, 28, 28).\n",
    "    N : int\n",
    "        The number of images to be used for calculating the FID score.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The FID score between the generated images and the real MNIST test images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select N real images from the standardized MNIST test data\n",
    "    real_images = standarized_test_data.reshape(-1, 1, 28, 28)\n",
    "    real_images = real_images[np.random.choice(real_images.shape[0], N)]\n",
    "\n",
    "    # Scale images to [-1, 1] range -> this is the range of pixels the \"mnist_frechet_distance\" expects\n",
    "    real_images = (\n",
    "        real_images.reshape(-1, 1, 28, 28).transpose(0, 2, 3, 1) - 0.5\n",
    "    ) * 2\n",
    "    real_images = tf.convert_to_tensor(real_images, dtype=tf.float32)\n",
    "\n",
    "    # Prepare the generated images\n",
    "    # Scale images to [-1, 1] range -> this is the range of pixels the \"mnist_frechet_distance\" expects\n",
    "    gen_x = (\n",
    "        np.array(generated_images).reshape(-1, 1, 28, 28).transpose(0, 2, 3, 1)\n",
    "        - 0.5\n",
    "    ) * 2\n",
    "    gen_x = tf.convert_to_tensor(gen_x, dtype=tf.float32)\n",
    "\n",
    "    # Calculate the number of batches for the FID computation\n",
    "    num_batches = int(np.ceil(N / 500))\n",
    "    num_batches = max(1, num_batches)\n",
    "    score = mnist_frechet_distance(real_images, gen_x, num_batches)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def vae_loss_function(recon_x, x, mu, logvar, vae_model):\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return KLD + vae_model.decoder.loss(recon_x, x)\n",
    "\n",
    "def compute_vae_error(model, test_loader, loss, loss_to_monitor):\n",
    "    loss_sum = 0\n",
    "    monitored_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            x = x[0].reshape(x[0].size(0), 1, image_dim, image_dim)\n",
    "\n",
    "            recon_batch, mu, logvar = model(x)\n",
    "            l = loss(recon_batch, x, mu, logvar, model)\n",
    "            monitored_loss += loss_to_monitor(recon_batch, x)\n",
    "            loss_sum += l\n",
    "\n",
    "    print(f\"Overall loss: {loss_sum / len(test_loader.dataset)}, Monitored loss: {monitored_loss / len(test_loader)}\")\n",
    "    return loss_sum / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemiDense\n",
    "The core of SarNET is a sparse linear layer. It is designed so that, except for the first neuron, each pixel/patch in the input is connected to the neurons corresponding to the subsequent pixel/patches. Additionaly, one can add connections from all the output neurons to the input latent vector.\n",
    "\n",
    "The SemiDense layer takes a flattened image as input and processes it pixel by pixel or patch by patch (depending on the configuration). The patches are subsequent squares of the image and do not overlap. The layer can be configured in two ways:\n",
    "\n",
    "- the 0-th output patch depends on the 0-th input patch, and the i-th output patch (for i>0) depends on the 0,...,(i-1)-th input patches (used in the first layer)\n",
    "- the i-th output patch depends on the 0,...,i-th input patches (used in deeper layers)\n",
    "\n",
    "The image below illustrates the second configuration. As shown, the last input patch is not connected to any neurons because we want to predict the last output patch based on the previous ones.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"docs/SemiDense_graph.png\" alt=\"SemiDense Graph\" width=\"500\">\n",
    "\n",
    "The design allows us to feed the entire flattened image into a network and obtain an output image of the same size. There is no need to \"shift\" the sequence as in transformer models.\n",
    "\n",
    "To preserve the autoregressive nature of the layer, the number of output pixels/patches should be the same as the number of input pixels/patches. The size of the input patches can vary the size of the output patches. For example, we can compress the image from patches of size 4x4 to patches of size 2x2 or 1x1. Conversely, we can expand the size of the patch to, for example, 8x8. Additionally, we can add channels to the input and output images—the architecture remains the same, but instead of looking at/predicting the patch in a single channel, we look at/predict the patch in every channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sarNET VAE SemiDense Autoregressive Network Variational AutoEncoder\n",
    "\n",
    "- The SarNET VAE leverages the advantages of a Variational AutoEncoder to enhance the generation process. First, it organizes the latent space using a convolutional encoder. Then, it feeds the input image into a stack of SemiDense layers. Each of the SemiDense layers has additional connections to the latent vector produced by the convolutional encoder.\n",
    "\n",
    "- Within the stack of SemiDense layers, the first layer is of type 1, meaning that the 0-th output patch depends on the 0-th input patch, and the i-th output patch (for $i>0$) depends on the 0,...,(i-1)-th input patches. Subsequent layers are of type 2, where the i-th output patch depends on the 0-th to i-th input patches (used in deeper layers). We decided to use three SemiDense layers. The first one compresses the input patches, the second one generates the image, and the last one refines the output.\n",
    "\n",
    "<img src=\"docs/sarNET_VAE.png\" alt=\"SemiDense Graph\" width=\"500\">\n",
    "\n",
    "- The loss function consists of the KLD loss and the reconstruction loss, which is BCE. We use BCE because we are dealing with black and white images, so we can interpret the output probability as the pixel intensity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (128 latent dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "patch_dim = 4\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "in_latent_dim = 128\n",
    "\n",
    "hidden_channels_1 = 2\n",
    "hidden_channels_2 = 2\n",
    "hidden_img_size = image_dim // 2\n",
    "hidden_patch_size = patch_dim // 2\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    SemiDense(image_dim, hidden_img_size, 1, hidden_channels_1, patch_dim, hidden_patch_size, shift=True, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(hidden_img_size, image_dim, hidden_channels_1, hidden_channels_2, hidden_patch_size, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(image_dim, image_dim, hidden_channels_2, 1, patch_dim, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "custom_loss = nn.MSELoss(reduction=\"mean\")\n",
    "bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "sarnet_vae = sarNet_VAE(layers, bce_loss, latent_dim, image_dim)\n",
    "sarnet_vae.to(device)\n",
    "optimizer = torch.optim.Adam(sarnet_vae.parameters(), lr=1e-3)\n",
    "train_loader, test_loader = prepare_dataset(\n",
    "    standarized_data, standarized_test_data, batch_size=64, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10 avg_los: 112.260611313\n",
      "Overall loss: 112.05719757080078, Monitored loss: 0.018442098051309586\n",
      "After epoch 20 avg_los: 101.449013025\n",
      "Overall loss: 103.9395751953125, Monitored loss: 0.014558536000549793\n",
      "After epoch 30 avg_los: 97.345225833\n",
      "Overall loss: 101.3819351196289, Monitored loss: 0.01372595690190792\n",
      "After epoch 40 avg_los: 94.967004762\n",
      "Overall loss: 100.54206085205078, Monitored loss: 0.013403907418251038\n",
      "After epoch 50 avg_los: 92.840517039\n",
      "Overall loss: 100.0642318725586, Monitored loss: 0.01323026791214943\n",
      "After epoch 60 avg_los: 91.151183891\n",
      "Overall loss: 99.87970733642578, Monitored loss: 0.01326003484427929\n",
      "After epoch 70 avg_los: 89.726038730\n",
      "Overall loss: 99.88835906982422, Monitored loss: 0.013276314362883568\n",
      "After epoch 80 avg_los: 88.594063361\n",
      "Overall loss: 100.32568359375, Monitored loss: 0.013733494095504284\n",
      "After epoch 90 avg_los: 87.439422591\n",
      "Overall loss: 100.4602279663086, Monitored loss: 0.013658459298312664\n",
      "After epoch 100 avg_los: 86.435334575\n",
      "Overall loss: 101.23148345947266, Monitored loss: 0.014108876697719097\n",
      "After epoch 110 avg_los: 85.586746078\n",
      "Overall loss: 101.4950180053711, Monitored loss: 0.014006072655320168\n",
      "After epoch 120 avg_los: 84.876824727\n",
      "Overall loss: 101.73648834228516, Monitored loss: 0.014134310185909271\n",
      "After epoch 130 avg_los: 84.172099685\n",
      "Overall loss: 102.45787048339844, Monitored loss: 0.014369769021868706\n",
      "After epoch 140 avg_los: 83.602736591\n",
      "Overall loss: 102.93948364257812, Monitored loss: 0.015026186592876911\n",
      "After epoch 150 avg_los: 83.034354968\n",
      "Overall loss: 103.55488586425781, Monitored loss: 0.01507510244846344\n",
      "After epoch 160 avg_los: 82.604129872\n",
      "Overall loss: 104.09840393066406, Monitored loss: 0.01518015656620264\n",
      "After epoch 170 avg_los: 81.986370279\n",
      "Overall loss: 104.43464660644531, Monitored loss: 0.015392227098345757\n",
      "After epoch 180 avg_los: 81.540712172\n",
      "Overall loss: 105.02918243408203, Monitored loss: 0.015432355925440788\n",
      "After epoch 190 avg_los: 81.213917358\n",
      "Overall loss: 105.21832275390625, Monitored loss: 0.01575593650341034\n",
      "After epoch 200 avg_los: 80.736920575\n",
      "Overall loss: 105.95198059082031, Monitored loss: 0.015964949503540993\n"
     ]
    }
   ],
   "source": [
    "model = sarnet_vae\n",
    "max_epochs = 200\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x in train_loader:\n",
    "        x = x[0].reshape(x[0].size(0), 1, 28, 28)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = vae_loss_function(recon_batch, x, mu, logvar, model)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"After epoch {epoch+1} avg_los: {avg_loss:.9f}\")\n",
    "        test_loss = compute_vae_error(model, test_loader, vae_loss_function, custom_loss)\n",
    "\n",
    "        '''if (epoch + 1) > 100:# == 0:\n",
    "            model.eval()\n",
    "            generated_images = []\n",
    "            N = 10000\n",
    "            num_of_images = 500\n",
    "            for num in tqdm(range(0, N, num_of_images)):\n",
    "                img = generate_image(\n",
    "                    model,\n",
    "                    patch_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    th=0.105,\n",
    "                    num_of_images=num_of_images,\n",
    "                    plot=False,\n",
    "                )\n",
    "\n",
    "                generated_images.append(img)\n",
    "\n",
    "            score = get_fid_score_mnist(generated_images, N)\n",
    "            if score < 1.45:\n",
    "                break\n",
    "            print(f\"FID\", score)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Best score with vector 128 latent dim:\n",
    "- mean FID: 1.5350 and std: 0.08037\n",
    "\n",
    "Best score with vector 64 latent dim:\n",
    "- mean FID: 1.5950 and std: 0.07689\n",
    "\n",
    "Best score with vector 32 latent dim:\n",
    "- mean FID: 1.5802 and std: 0.08526\n",
    "\n",
    "Best score with vector 16 latent dim:\n",
    "- mean FID: 1.6140 and std: 0.04884\n",
    "\n",
    "Best score with vector 8 latent dim:\n",
    "- mean FID: 2.1251 and std: 0.08887\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10 avg_los: 110.680290623\n",
      "Overall loss: 110.40888214111328, Monitored loss: 0.01765618845820427\n",
      "After epoch 20 avg_los: 101.688049620\n",
      "Overall loss: 103.58287811279297, Monitored loss: 0.014414125122129917\n",
      "After epoch 30 avg_los: 98.130812537\n",
      "Overall loss: 101.11072540283203, Monitored loss: 0.013033402152359486\n",
      "After epoch 40 avg_los: 95.726130604\n",
      "Overall loss: 100.39429473876953, Monitored loss: 0.013002746738493443\n",
      "After epoch 50 avg_los: 94.000004143\n",
      "Overall loss: 99.6449203491211, Monitored loss: 0.012383217923343182\n",
      "After epoch 60 avg_los: 92.579872851\n",
      "Overall loss: 99.48002624511719, Monitored loss: 0.012343969196081161\n",
      "After epoch 70 avg_los: 91.372130931\n",
      "Overall loss: 99.21592712402344, Monitored loss: 0.012812693603336811\n",
      "After epoch 80 avg_los: 90.300996432\n",
      "Overall loss: 99.18836975097656, Monitored loss: 0.012853293679654598\n",
      "After epoch 90 avg_los: 89.391624936\n",
      "Overall loss: 99.16051483154297, Monitored loss: 0.012826468795537949\n",
      "After epoch 100 avg_los: 88.514582595\n",
      "Overall loss: 99.3322525024414, Monitored loss: 0.012980611994862556\n",
      "After epoch 110 avg_los: 87.691348604\n",
      "Overall loss: 99.84210968017578, Monitored loss: 0.01322570163756609\n",
      "After epoch 120 avg_los: 87.165766485\n",
      "Overall loss: 100.04244995117188, Monitored loss: 0.013254089280962944\n",
      "After epoch 130 avg_los: 86.488083587\n",
      "Overall loss: 100.3089599609375, Monitored loss: 0.013200076296925545\n",
      "After epoch 140 avg_los: 85.904964850\n",
      "Overall loss: 100.77924346923828, Monitored loss: 0.013617944903671741\n",
      "After epoch 150 avg_los: 85.299808155\n",
      "Overall loss: 100.7699203491211, Monitored loss: 0.013652203604578972\n",
      "After epoch 160 avg_los: 84.926988577\n",
      "Overall loss: 101.59503173828125, Monitored loss: 0.013775254599750042\n",
      "After epoch 170 avg_los: 84.528035414\n",
      "Overall loss: 101.64522552490234, Monitored loss: 0.01389903761446476\n",
      "After epoch 180 avg_los: 84.031184112\n",
      "Overall loss: 102.18274688720703, Monitored loss: 0.014239247888326645\n",
      "After epoch 190 avg_los: 83.609611530\n",
      "Overall loss: 102.41515350341797, Monitored loss: 0.014396551065146923\n",
      "After epoch 200 avg_los: 83.225152961\n",
      "Overall loss: 102.43106079101562, Monitored loss: 0.014295210130512714\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "in_latent_dim = 64\n",
    "\n",
    "hidden_channels_1 = 1\n",
    "hidden_channels_2 = 2\n",
    "hidden_img_size = image_dim // 2\n",
    "hidden_patch_size = patch_dim // 2\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    SemiDense(image_dim, hidden_img_size, 1, hidden_channels_1, patch_dim, hidden_patch_size, shift=True, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(hidden_img_size, image_dim, hidden_channels_1, hidden_channels_2, hidden_patch_size, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(image_dim, image_dim, hidden_channels_2, 1, patch_dim, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "custom_loss = nn.MSELoss(reduction=\"mean\")\n",
    "bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "sarnet_vae = sarNet_VAE(layers, bce_loss, latent_dim, image_dim)\n",
    "sarnet_vae.to(device)\n",
    "optimizer = torch.optim.Adam(sarnet_vae.parameters(), lr=1e-3)\n",
    "train_loader, test_loader = prepare_dataset(\n",
    "    standarized_data, standarized_test_data, batch_size=64, device=device\n",
    ")\n",
    "\n",
    "model = sarnet_vae\n",
    "max_epochs = 200\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x in train_loader:\n",
    "        x = x[0].reshape(x[0].size(0), 1, 28, 28)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = vae_loss_function(recon_batch, x, mu, logvar, model)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"After epoch {epoch+1} avg_los: {avg_loss:.9f}\")\n",
    "        test_loss = compute_vae_error(model, test_loader, vae_loss_function, custom_loss)\n",
    "\n",
    "        '''if (epoch + 1) > 50:# == 0:\n",
    "            model.eval()\n",
    "            generated_images = []\n",
    "            N = 800\n",
    "            num_of_images = 400\n",
    "            for num in tqdm(range(0, N, num_of_images)):\n",
    "                img = generate_image(\n",
    "                    model,\n",
    "                    patch_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    th=0.105,\n",
    "                    num_of_images=num_of_images,\n",
    "                    plot=False,\n",
    "                )\n",
    "\n",
    "                generated_images.append(img)\n",
    "\n",
    "            score = get_fid_score_mnist(generated_images, N)\n",
    "            print(f\"FID\", score)\n",
    "            if score < 1.45:\n",
    "                break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:07<01:10,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 0 tf.Tensor(1.4521933, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:15<01:00,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 1 tf.Tensor(1.7141283, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:22<00:52,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 2 tf.Tensor(1.6111147, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:30<00:45,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 3 tf.Tensor(1.5877134, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:38<00:38,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 4 tf.Tensor(1.5936435, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:46<00:31,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 5 tf.Tensor(1.615664, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:53<00:22,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 6 tf.Tensor(1.6733835, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:00<00:15,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 7 tf.Tensor(1.4662293, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:08<00:07,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 8 tf.Tensor(1.6195205, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:15<00:00,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 9 tf.Tensor(1.6165888, shape=(), dtype=float32)\n",
      "FID mean score: 1.5950178 FID std score: 0.076889604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "N = 10000\n",
    "num_of_images = 500\n",
    "\n",
    "scores = []\n",
    "eval_seed = 2024\n",
    "torch.manual_seed(eval_seed)\n",
    "np.random.seed(eval_seed)\n",
    "\n",
    "model = sarnet_vae\n",
    "\n",
    "for i in tqdm(range(num_experiments)):\n",
    "    generated_images = []\n",
    "    for num in range(0, N, num_of_images):\n",
    "        img = generate_image(\n",
    "            model,\n",
    "            patch_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            th=0.105,\n",
    "            num_of_images=num_of_images,\n",
    "            plot=False,\n",
    "        )\n",
    "\n",
    "        generated_images.append(img)\n",
    "    score = get_fid_score_mnist(generated_images, N)\n",
    "    scores.append(score)\n",
    "    print(f\"FID in {i}\", score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"FID mean score:\", scores.mean(), \"FID std score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32 latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "in_latent_dim = 32\n",
    "\n",
    "hidden_channels_1 = 1\n",
    "hidden_channels_2 = 2\n",
    "hidden_img_size = image_dim // 2\n",
    "hidden_patch_size = patch_dim // 2\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    SemiDense(image_dim, hidden_img_size, 1, hidden_channels_1, patch_dim, hidden_patch_size, shift=True, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(hidden_img_size, image_dim, hidden_channels_1, hidden_channels_2, hidden_patch_size, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(image_dim, image_dim, hidden_channels_2, 1, patch_dim, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "custom_loss = nn.MSELoss(reduction=\"mean\")\n",
    "bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "sarnet_vae = sarNet_VAE(layers, bce_loss, latent_dim, image_dim)\n",
    "sarnet_vae.to(device)\n",
    "optimizer = torch.optim.Adam(sarnet_vae.parameters(), lr=1e-3)\n",
    "train_loader, test_loader = prepare_dataset(\n",
    "    standarized_data, standarized_test_data, batch_size=64, device=device\n",
    ")\n",
    "\n",
    "model = sarnet_vae\n",
    "max_epochs = 200\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x in train_loader:\n",
    "        x = x[0].reshape(x[0].size(0), 1, 28, 28)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = vae_loss_function(recon_batch, x, mu, logvar, model)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"After epoch {epoch+1} avg_los: {avg_loss:.9f}\")\n",
    "        test_loss = compute_vae_error(model, test_loader, vae_loss_function, custom_loss)\n",
    "\n",
    "        '''if (epoch + 1) > 50:# == 0:\n",
    "            model.eval()\n",
    "            generated_images = []\n",
    "            N = 800\n",
    "            num_of_images = 400\n",
    "            for num in tqdm(range(0, N, num_of_images)):\n",
    "                img = generate_image(\n",
    "                    model,\n",
    "                    patch_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    th=0.105,\n",
    "                    num_of_images=num_of_images,\n",
    "                    plot=False,\n",
    "                )\n",
    "\n",
    "                generated_images.append(img)\n",
    "\n",
    "            score = get_fid_score_mnist(generated_images, N)\n",
    "            print(f\"FID\", score)\n",
    "            if score < 1.45:\n",
    "                break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:55,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 0 tf.Tensor(1.5949084, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:12<00:50,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 1 tf.Tensor(1.5847245, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:18<00:43,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 2 tf.Tensor(1.5949374, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:24<00:35,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 3 tf.Tensor(1.6816698, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:29<00:28,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 4 tf.Tensor(1.5028503, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:34<00:22,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 5 tf.Tensor(1.6230314, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:40<00:16,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 6 tf.Tensor(1.5497816, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:45<00:10,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 7 tf.Tensor(1.4020714, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:50<00:05,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 8 tf.Tensor(1.5455517, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:56<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 9 tf.Tensor(1.7225415, shape=(), dtype=float32)\n",
      "FID mean score: 1.5802068 FID std score: 0.085255094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "N = 10000\n",
    "num_of_images = 500\n",
    "\n",
    "scores = []\n",
    "eval_seed = 2024\n",
    "torch.manual_seed(eval_seed)\n",
    "np.random.seed(eval_seed)\n",
    "\n",
    "model = sarnet_vae\n",
    "\n",
    "for i in tqdm(range(num_experiments)):\n",
    "    generated_images = []\n",
    "    for num in range(0, N, num_of_images):\n",
    "        img = generate_image(\n",
    "            model,\n",
    "            patch_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            th=0.105,\n",
    "            num_of_images=num_of_images,\n",
    "            plot=False,\n",
    "        )\n",
    "\n",
    "        generated_images.append(img)\n",
    "    score = get_fid_score_mnist(generated_images, N)\n",
    "    scores.append(score)\n",
    "    print(f\"FID in {i}\", score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"FID mean score:\", scores.mean(), \"FID std score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10 avg_los: 109.169702549\n",
      "Overall loss: 108.89692687988281, Monitored loss: 0.0171610489487648\n",
      "After epoch 20 avg_los: 100.268544239\n",
      "Overall loss: 102.06881713867188, Monitored loss: 0.013553053140640259\n",
      "After epoch 30 avg_los: 96.781879064\n",
      "Overall loss: 99.88406372070312, Monitored loss: 0.01283738948404789\n",
      "After epoch 40 avg_los: 94.497967071\n",
      "Overall loss: 98.92623901367188, Monitored loss: 0.012590044178068638\n",
      "After epoch 50 avg_los: 92.795353050\n",
      "Overall loss: 98.51722717285156, Monitored loss: 0.012706193141639233\n",
      "After epoch 60 avg_los: 91.385481248\n",
      "Overall loss: 97.96028900146484, Monitored loss: 0.01243249885737896\n",
      "After epoch 70 avg_los: 90.162527445\n",
      "Overall loss: 97.93565368652344, Monitored loss: 0.012746850959956646\n",
      "After epoch 80 avg_los: 89.216707478\n",
      "Overall loss: 97.89873504638672, Monitored loss: 0.012687018141150475\n",
      "After epoch 90 avg_los: 88.308257691\n",
      "Overall loss: 98.3504409790039, Monitored loss: 0.01285457331687212\n",
      "After epoch 100 avg_los: 87.516530676\n",
      "Overall loss: 98.21451568603516, Monitored loss: 0.013016371056437492\n",
      "After epoch 110 avg_los: 86.788399028\n",
      "Overall loss: 98.57257080078125, Monitored loss: 0.01314627006649971\n",
      "After epoch 120 avg_los: 86.158831649\n",
      "Overall loss: 98.98031616210938, Monitored loss: 0.013208809308707714\n",
      "After epoch 130 avg_los: 85.610739413\n",
      "Overall loss: 99.09141540527344, Monitored loss: 0.013527710922062397\n",
      "After epoch 140 avg_los: 85.100200609\n",
      "Overall loss: 99.80245208740234, Monitored loss: 0.013735609129071236\n",
      "After epoch 150 avg_los: 84.492393630\n",
      "Overall loss: 99.43478393554688, Monitored loss: 0.013548184186220169\n",
      "After epoch 160 avg_los: 84.071574771\n",
      "Overall loss: 100.06614685058594, Monitored loss: 0.013897441327571869\n",
      "After epoch 170 avg_los: 83.746354599\n",
      "Overall loss: 100.50537109375, Monitored loss: 0.013845670036971569\n",
      "After epoch 180 avg_los: 83.373507954\n",
      "Overall loss: 100.58890533447266, Monitored loss: 0.014008015394210815\n",
      "After epoch 190 avg_los: 82.869401114\n",
      "Overall loss: 101.22991943359375, Monitored loss: 0.014349187724292278\n",
      "After epoch 200 avg_los: 82.532388152\n",
      "Overall loss: 101.57118225097656, Monitored loss: 0.01437049824744463\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "in_latent_dim = 16\n",
    "\n",
    "hidden_channels_1 = 1\n",
    "hidden_channels_2 = 2\n",
    "hidden_img_size = image_dim // 2\n",
    "hidden_patch_size = patch_dim // 2\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    SemiDense(image_dim, hidden_img_size, 1, hidden_channels_1, patch_dim, hidden_patch_size, shift=True, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(hidden_img_size, image_dim, hidden_channels_1, hidden_channels_2, hidden_patch_size, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(image_dim, image_dim, hidden_channels_2, 1, patch_dim, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "custom_loss = nn.MSELoss(reduction=\"mean\")\n",
    "bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "sarnet_vae = sarNet_VAE(layers, bce_loss, latent_dim, image_dim)\n",
    "sarnet_vae.to(device)\n",
    "optimizer = torch.optim.Adam(sarnet_vae.parameters(), lr=1e-3)\n",
    "train_loader, test_loader = prepare_dataset(\n",
    "    standarized_data, standarized_test_data, batch_size=64, device=device\n",
    ")\n",
    "\n",
    "model = sarnet_vae\n",
    "max_epochs = 200\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x in train_loader:\n",
    "        x = x[0].reshape(x[0].size(0), 1, 28, 28)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = vae_loss_function(recon_batch, x, mu, logvar, model)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"After epoch {epoch+1} avg_los: {avg_loss:.9f}\")\n",
    "        test_loss = compute_vae_error(model, test_loader, vae_loss_function, custom_loss)\n",
    "\n",
    "        '''if (epoch + 1) > 50:# == 0:\n",
    "            model.eval()\n",
    "            generated_images = []\n",
    "            N = 800\n",
    "            num_of_images = 400\n",
    "            for num in tqdm(range(0, N, num_of_images)):\n",
    "                img = generate_image(\n",
    "                    model,\n",
    "                    patch_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    th=0.105,\n",
    "                    num_of_images=num_of_images,\n",
    "                    plot=False,\n",
    "                )\n",
    "\n",
    "                generated_images.append(img)\n",
    "\n",
    "            score = get_fid_score_mnist(generated_images, N)\n",
    "            print(f\"FID\", score)\n",
    "            if score < 1.45:\n",
    "                break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:49,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 0 tf.Tensor(1.6294726, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:43,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 1 tf.Tensor(1.6024597, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:16<00:37,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 2 tf.Tensor(1.4953249, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:21<00:31,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 3 tf.Tensor(1.5787169, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:26<00:25,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 4 tf.Tensor(1.6506029, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:31<00:20,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 5 tf.Tensor(1.6374544, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:36<00:15,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 6 tf.Tensor(1.617726, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:41<00:10,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 7 tf.Tensor(1.6682523, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:46<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 8 tf.Tensor(1.5926257, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:52<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 9 tf.Tensor(1.6674019, shape=(), dtype=float32)\n",
      "FID mean score: 1.6140038 FID std score: 0.048843607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "N = 10000\n",
    "num_of_images = 500\n",
    "\n",
    "scores = []\n",
    "eval_seed = 2024\n",
    "torch.manual_seed(eval_seed)\n",
    "np.random.seed(eval_seed)\n",
    "\n",
    "model = sarnet_vae\n",
    "\n",
    "for i in tqdm(range(num_experiments)):\n",
    "    generated_images = []\n",
    "    for num in range(0, N, num_of_images):\n",
    "        img = generate_image(\n",
    "            model,\n",
    "            patch_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            th=0.105,\n",
    "            num_of_images=num_of_images,\n",
    "            plot=False,\n",
    "        )\n",
    "\n",
    "        generated_images.append(img)\n",
    "    score = get_fid_score_mnist(generated_images, N)\n",
    "    scores.append(score)\n",
    "    print(f\"FID in {i}\", score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"FID mean score:\", scores.mean(), \"FID std score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10 avg_los: 110.580780598\n",
      "Overall loss: 110.68486022949219, Monitored loss: 0.01926465705037117\n",
      "After epoch 20 avg_los: 101.662504612\n",
      "Overall loss: 103.98209381103516, Monitored loss: 0.01624610833823681\n",
      "After epoch 30 avg_los: 97.582213736\n",
      "Overall loss: 101.32283020019531, Monitored loss: 0.014811907894909382\n",
      "After epoch 40 avg_los: 94.649006666\n",
      "Overall loss: 100.26241302490234, Monitored loss: 0.014245101250708103\n",
      "After epoch 50 avg_los: 92.694809267\n",
      "Overall loss: 99.70991516113281, Monitored loss: 0.014412852935492992\n",
      "After epoch 60 avg_los: 90.935289629\n",
      "Overall loss: 99.42066192626953, Monitored loss: 0.014052118174731731\n",
      "After epoch 70 avg_los: 89.541773492\n",
      "Overall loss: 98.9957275390625, Monitored loss: 0.01390837598592043\n",
      "After epoch 80 avg_los: 88.390013860\n",
      "Overall loss: 99.11201477050781, Monitored loss: 0.013992482796311378\n",
      "After epoch 90 avg_los: 87.337165139\n",
      "Overall loss: 99.3140640258789, Monitored loss: 0.014063114300370216\n",
      "After epoch 100 avg_los: 86.463396560\n",
      "Overall loss: 99.93278503417969, Monitored loss: 0.014371040277183056\n",
      "After epoch 110 avg_los: 85.624826881\n",
      "Overall loss: 99.75211334228516, Monitored loss: 0.01433686912059784\n",
      "After epoch 120 avg_los: 84.969424190\n",
      "Overall loss: 100.26889038085938, Monitored loss: 0.014509663917124271\n",
      "After epoch 130 avg_los: 84.352832698\n",
      "Overall loss: 100.64965057373047, Monitored loss: 0.014490003697574139\n",
      "After epoch 140 avg_los: 83.765951241\n",
      "Overall loss: 101.08106231689453, Monitored loss: 0.014619026333093643\n",
      "After epoch 150 avg_los: 83.104439495\n",
      "Overall loss: 101.38936614990234, Monitored loss: 0.014797668904066086\n",
      "After epoch 160 avg_los: 82.753768169\n",
      "Overall loss: 101.88041687011719, Monitored loss: 0.014989037998020649\n",
      "After epoch 170 avg_los: 82.303063138\n",
      "Overall loss: 102.04998016357422, Monitored loss: 0.01489155925810337\n",
      "After epoch 180 avg_los: 81.936747537\n",
      "Overall loss: 103.07756042480469, Monitored loss: 0.015193292871117592\n",
      "After epoch 190 avg_los: 81.557713249\n",
      "Overall loss: 103.48139953613281, Monitored loss: 0.015409444458782673\n",
      "After epoch 200 avg_los: 81.185831548\n",
      "Overall loss: 104.01669311523438, Monitored loss: 0.015470219776034355\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 8\n",
    "in_latent_dim = 8\n",
    "\n",
    "hidden_channels_1 = 1\n",
    "hidden_channels_2 = 2\n",
    "hidden_img_size = image_dim // 2\n",
    "hidden_patch_size = patch_dim // 2\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "layers = nn.Sequential(\n",
    "    SemiDense(image_dim, hidden_img_size, 1, hidden_channels_1, patch_dim, hidden_patch_size, shift=True, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(hidden_img_size, image_dim, hidden_channels_1, hidden_channels_2, hidden_patch_size, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.ReLU(),\n",
    "    SemiDense(image_dim, image_dim, hidden_channels_2, 1, patch_dim, patch_dim, shift=False, latent_dim=in_latent_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "custom_loss = nn.MSELoss(reduction=\"mean\")\n",
    "bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "sarnet_vae = sarNet_VAE(layers, bce_loss, latent_dim, image_dim)\n",
    "sarnet_vae.to(device)\n",
    "optimizer = torch.optim.Adam(sarnet_vae.parameters(), lr=1e-3)\n",
    "train_loader, test_loader = prepare_dataset(\n",
    "    standarized_data, standarized_test_data, batch_size=64, device=device\n",
    ")\n",
    "\n",
    "model = sarnet_vae\n",
    "max_epochs = 200\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x in train_loader:\n",
    "        x = x[0].reshape(x[0].size(0), 1, 28, 28)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = vae_loss_function(recon_batch, x, mu, logvar, model)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    avg_loss /= len(train_loader.dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"After epoch {epoch+1} avg_los: {avg_loss:.9f}\")\n",
    "        test_loss = compute_vae_error(model, test_loader, vae_loss_function, custom_loss)\n",
    "\n",
    "        '''if (epoch + 1) > 50:# == 0:\n",
    "            model.eval()\n",
    "            generated_images = []\n",
    "            N = 800\n",
    "            num_of_images = 400\n",
    "            for num in tqdm(range(0, N, num_of_images)):\n",
    "                img = generate_image(\n",
    "                    model,\n",
    "                    patch_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    th=0.105,\n",
    "                    num_of_images=num_of_images,\n",
    "                    plot=False,\n",
    "                )\n",
    "\n",
    "                generated_images.append(img)\n",
    "\n",
    "            score = get_fid_score_mnist(generated_images, N)\n",
    "            print(f\"FID\", score)\n",
    "            if score < 1.45:\n",
    "                break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:45,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 0 tf.Tensor(2.0778663, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:11<00:45,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 1 tf.Tensor(2.2859743, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:16<00:39,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 2 tf.Tensor(2.0576282, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:22<00:33,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 3 tf.Tensor(1.9714533, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:27<00:28,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 4 tf.Tensor(2.1391666, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:33<00:22,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 5 tf.Tensor(2.1984015, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:39<00:17,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 6 tf.Tensor(2.176451, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:45<00:11,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 7 tf.Tensor(2.0279753, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:50<00:05,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 8 tf.Tensor(2.1198962, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:57<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 9 tf.Tensor(2.1960633, shape=(), dtype=float32)\n",
      "FID mean score: 2.1250875 FID std score: 0.08886803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "N = 10000\n",
    "num_of_images = 500\n",
    "\n",
    "scores = []\n",
    "eval_seed = 2024\n",
    "torch.manual_seed(eval_seed)\n",
    "np.random.seed(eval_seed)\n",
    "\n",
    "model = sarnet_vae\n",
    "\n",
    "for i in tqdm(range(num_experiments)):\n",
    "    generated_images = []\n",
    "    for num in range(0, N, num_of_images):\n",
    "        img = generate_image(\n",
    "            model,\n",
    "            patch_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            th=0.095,\n",
    "            num_of_images=num_of_images,\n",
    "            plot=False,\n",
    "        )\n",
    "\n",
    "        generated_images.append(img)\n",
    "    score = get_fid_score_mnist(generated_images, N)\n",
    "    scores.append(score)\n",
    "    print(f\"FID in {i}\", score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"FID mean score:\", scores.mean(), \"FID std score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean FID score in 50 experiments (latent dim 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:07<05:48,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 0 tf.Tensor(1.5064803, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:13<05:28,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 1 tf.Tensor(1.6412711, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:19<05:04,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 2 tf.Tensor(1.5744945, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:25<04:48,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 3 tf.Tensor(1.6110754, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:31<04:36,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 4 tf.Tensor(1.4232639, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:37<04:26,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 5 tf.Tensor(1.484615, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:43<04:17,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 6 tf.Tensor(1.5062383, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:49<04:15,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 7 tf.Tensor(1.376687, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:56<04:16,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 8 tf.Tensor(1.5109735, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:02<04:05,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 9 tf.Tensor(1.6637442, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:08<03:55,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 10 tf.Tensor(1.5076498, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:13<03:47,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 11 tf.Tensor(1.5369129, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:19<03:41,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 12 tf.Tensor(1.4217148, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:28<04:04,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 13 tf.Tensor(1.6384152, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:37<04:20,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 14 tf.Tensor(1.5757356, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:45<04:16,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 15 tf.Tensor(1.6480758, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:53<04:12,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 16 tf.Tensor(1.5841904, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:00<04:04,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 17 tf.Tensor(1.5352811, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:08<03:59,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 18 tf.Tensor(1.5073098, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:18<04:07,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 19 tf.Tensor(1.4826853, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [02:27<04:10,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 20 tf.Tensor(1.5737637, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [02:35<03:53,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 21 tf.Tensor(1.7204905, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:43<03:42,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 22 tf.Tensor(1.4460676, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [02:51<03:29,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 23 tf.Tensor(1.4777502, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:59<03:21,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 24 tf.Tensor(1.5379815, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [03:07<03:17,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 25 tf.Tensor(1.5446373, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [03:15<03:09,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 26 tf.Tensor(1.452112, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [03:24<03:01,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 27 tf.Tensor(1.4359276, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [03:32<02:54,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 28 tf.Tensor(1.6517402, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:41<02:50,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 29 tf.Tensor(1.4883446, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [03:49<02:39,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 30 tf.Tensor(1.5183897, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [03:59<02:35,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 31 tf.Tensor(1.5628728, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [04:08<02:30,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 32 tf.Tensor(1.4964213, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [04:17<02:21,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 33 tf.Tensor(1.4377549, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:28<02:24,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 34 tf.Tensor(1.4400384, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [04:38<02:14,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 35 tf.Tensor(1.5157309, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [04:47<02:02,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 36 tf.Tensor(1.451925, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [04:56<01:54,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 37 tf.Tensor(1.6176131, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [05:06<01:44,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 38 tf.Tensor(1.6772692, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:18<01:41, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 39 tf.Tensor(1.662778, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [05:29<01:35, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 40 tf.Tensor(1.5104998, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [05:38<01:21, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 41 tf.Tensor(1.5088065, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [05:44<01:00,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 42 tf.Tensor(1.6617346, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [05:50<00:48,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 43 tf.Tensor(1.4216286, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:01<00:43,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 44 tf.Tensor(1.5414853, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [06:23<00:51, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 45 tf.Tensor(1.53044, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [06:30<00:33, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 46 tf.Tensor(1.4274075, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [06:37<00:19,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 47 tf.Tensor(1.620815, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [06:43<00:08,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 48 tf.Tensor(1.5336194, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:48<00:00,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID in 49 tf.Tensor(1.5509784, shape=(), dtype=float32)\n",
      "FID mean score: 1.5350769 FID std score: 0.080374084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 50\n",
    "N = 10000\n",
    "num_of_images = 500\n",
    "\n",
    "scores = []\n",
    "eval_seed = 2024\n",
    "torch.manual_seed(eval_seed)\n",
    "np.random.seed(eval_seed)\n",
    "\n",
    "model = sarnet_vae\n",
    "\n",
    "for i in tqdm(range(num_experiments)):\n",
    "    generated_images = []\n",
    "    for num in range(0, N, num_of_images):\n",
    "        img = generate_image(\n",
    "            model,\n",
    "            patch_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            th=0.105,\n",
    "            num_of_images=num_of_images,\n",
    "            plot=False,\n",
    "        )\n",
    "\n",
    "        generated_images.append(img)\n",
    "    score = get_fid_score_mnist(generated_images, N)\n",
    "    scores.append(score)\n",
    "    print(f\"FID in {i}\", score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"FID mean score:\", scores.mean(), \"FID std score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the score of KNN discriminator (latent dim 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# prepare the generated and original data\n",
    "\n",
    "generated_images = []\n",
    "N, num_of_images = 1000, 500\n",
    "for num in tqdm(range(0, N, num_of_images)):\n",
    "    img = generate_image(\n",
    "        model,\n",
    "        patch_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        th=0.095,\n",
    "        num_of_images=num_of_images,\n",
    "        plot=False,\n",
    "    )\n",
    "    generated_images.append(img)\n",
    "\n",
    "X_gen = np.array(generated_images).reshape(N, -1)\n",
    "X_orig = standarized_test_data[np.random.choice(standarized_test_data.shape[0], N, replace=True)].reshape(N, -1)\n",
    "\n",
    "X = np.vstack([X_orig, X_gen])\n",
    "y = np.array(X_orig.shape[0] * [1] + X_gen.shape[0] * [0])\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.17%\n"
     ]
    }
   ],
   "source": [
    "# Create kNN classifier. You can adjust the number of neighbors (n_neighbors)\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generating the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Displaying the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(\n",
    "    pd.DataFrame(cm, dtype=int),\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Generated\", \"True\"],  # data.target_names,\n",
    "    yticklabels=[\"Generated\", \"True\"],  # ata.target_names,\n",
    ")\n",
    "#ax.text(0.5, 1.5, cm[1, 0])\n",
    "#ax.text(1.5, 1.5, cm[1, 1])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix for custom Transformer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 19.54it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_imgs = []\n",
    "num_of_images = 20\n",
    "columns = 5\n",
    "rows = math.ceil(num_of_images / columns)\n",
    "\n",
    "np.random.seed(seed=20)\n",
    "for i in tqdm(range(num_of_images)):\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    img = generate_image(\n",
    "        sarnet_vae,\n",
    "        patch_dim,\n",
    "        th = 0.105,\n",
    "        latent_dim=latent_dim\n",
    "    )\n",
    "    generated_imgs.append(img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction part of an image\n",
    "Here instead of using random latent vector from $N(0,1)$, we use \n",
    "random latent vector from $N(0, (\\frac{2}{3})^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 22.23it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_reconstruct = standarized_test_data[9]\n",
    "pixels_seed = 384\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(to_reconstruct, cmap=\"gray\")\n",
    "start_image, indexes_of_patches = init_image(\n",
    "    patch_dim, to_reconstruct, pixels_seed=pixels_seed\n",
    ")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(start_image.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "generated_imgs = []\n",
    "num_of_images = 20\n",
    "columns = 5\n",
    "rows = math.ceil(num_of_images / columns)\n",
    "\n",
    "np.random.seed(seed=20)\n",
    "for i in tqdm(range(num_of_images)):\n",
    "    plt.subplot(rows, columns, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    img = generate_image(\n",
    "        sarnet_vae,\n",
    "        patch_dim,\n",
    "        image=standarized_test_data[9],\n",
    "        th=0.15,\n",
    "        pixels_seed=384,\n",
    "        latent_dim=latent_dim,\n",
    "        cust_z=torch.randn(1, latent_dim).to(\"cuda\") / 1.5,\n",
    "    )\n",
    "    generated_imgs.append(img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
